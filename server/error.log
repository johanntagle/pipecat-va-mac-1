% uv run 06_parallel_tts_warmup.py 2 
2025-11-15 02:18:39.455 | INFO     | pipecat:<module>:14 - á“šá˜á—¢ Pipecat 0.0.81 (Python 3.13.7 (main, Sep  2 2025, 14:05:52) [Clang 20.1.4 ]) á“šá˜á—¢
2025-11-15 02:18:44.647 | INFO     | __main__:load_company_config:553 - Loading company configuration for ID: 2
2025-11-15 02:18:44.685 | INFO     | __main__:load_company_config:571 -   - Using custom RAG instructions from database
2025-11-15 02:18:44.686 | INFO     | __main__:load_company_config:576 - âœ“ Loaded configuration for: Tomatitos 2
2025-11-15 02:18:44.686 | INFO     | __main__:load_company_config:577 -   - LLM Model: gpt-4o
2025-11-15 02:18:44.686 | INFO     | __main__:load_company_config:578 -   - System Prompt: You are Lenny, the concierge for Tomatito Sexy Tapas Barâ€”a vibrant, funky Spanish-inspired venue tha...
2025-11-15 02:18:44.686 | INFO     | __main__:load_company_config:579 -   - RAG enabled with threshold: 0.7
2025-11-15 02:18:44.686 | INFO     | __main__:preload_models:524 - ============================================================
2025-11-15 02:18:44.686 | INFO     | __main__:preload_models:525 - PRELOADING MODELS FOR FAST STARTUP
2025-11-15 02:18:44.686 | INFO     | __main__:preload_models:526 - ============================================================
2025-11-15 02:18:44.686 | INFO     | __main__:preload_models:529 - 1/2 Loading Silero VAD model...
2025-11-15 02:18:44.686 | DEBUG    | pipecat.audio.vad.silero:__init__:147 - Loading Silero VAD model...
2025-11-15 02:18:44.754 | DEBUG    | pipecat.audio.vad.silero:__init__:169 - Loaded Silero VAD
2025-11-15 02:18:44.754 | INFO     | __main__:preload_models:533 -   âœ“ VAD loaded in 0.07s
2025-11-15 02:18:44.754 | INFO     | __main__:preload_models:536 - 2/2 Loading Local Smart Turn v2 model (this may take 20-30 seconds)...
2025-11-15 02:18:44.754 | DEBUG    | pipecat.audio.turn.smart_turn.local_smart_turn_v2:__init__:60 - Loading Local Smart Turn v2 model...
2025-11-15 02:18:48.368 | DEBUG    | pipecat.audio.turn.smart_turn.local_smart_turn_v2:__init__:74 - Loaded Local Smart Turn v2
2025-11-15 02:18:48.368 | INFO     | __main__:preload_models:543 -   âœ“ Smart Turn loaded in 3.61s
2025-11-15 02:18:48.368 | INFO     | __main__:preload_models:545 - ============================================================
2025-11-15 02:18:48.368 | INFO     | __main__:preload_models:546 - âœ“ ALL MODELS PRELOADED - Ready for instant connections!
2025-11-15 02:18:48.368 | INFO     | __main__:preload_models:547 - ============================================================
INFO:     Started server process [98762]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://localhost:7860 (Press CTRL+C to quit)
2025-11-15 02:18:53.450 | DEBUG    | pipecat.transports.network.webrtc_connection:_initialize:234 - Initializing new peer connection
2025-11-15 02:18:53.462 | DEBUG    | pipecat.transports.network.webrtc_connection:_create_answer:320 - Creating answer
2025-11-15 02:18:53.463 | DEBUG    | pipecat.transports.network.webrtc_connection:on_track:302 - Track audio received
2025-11-15 02:18:53.463 | DEBUG    | pipecat.transports.network.webrtc_connection:on_track:302 - Track video received
2025-11-15 02:18:53.465 | DEBUG    | pipecat.transports.network.webrtc_connection:on_icegatheringstatechange:298 - ICE gathering state is gathering
2025-11-15 02:18:53.546 | DEBUG    | pipecat.transports.network.webrtc_connection:on_icegatheringstatechange:298 - ICE gathering state is complete
2025-11-15 02:18:53.547 | DEBUG    | pipecat.transports.network.webrtc_connection:_create_answer:323 - Setting the answer after the local description is created
INFO:     127.0.0.1:65109 - "POST /api/offer HTTP/1.1" 200 OK
2025-11-15 02:18:53.548 | INFO     | __main__:run_bot:333 - Using preloaded VAD and Smart Turn models for fast startup
2025-11-15 02:18:53.549 | INFO     | tts_mlx_isolated:_get_worker_script_path:67 - Using worker script: /Users/johanntagle/LEARN/macos-local-voice-agents/server/kokoro_worker.py
/Users/johanntagle/LEARN/macos-local-voice-agents/server/.venv/lib/python3.13/site-packages/pipecat/services/llm_service.py:292: DeprecationWarning: Function calls with parameters `(function_name, tool_call_id, arguments, llm, context, result_callback)` are deprecated, use a single `FunctionCallParams` parameter instead.
  warnings.warn(
2025-11-15 02:18:53.576 | DEBUG    | pipecat.processors.frame_processor:link:499 - Linking Pipeline#0::Source -> SmallWebRTCInputTransport#0
2025-11-15 02:18:53.576 | DEBUG    | pipecat.processors.frame_processor:link:499 - Linking SmallWebRTCInputTransport#0 -> WhisperSTTServiceMLX#0
2025-11-15 02:18:53.576 | DEBUG    | pipecat.processors.frame_processor:link:499 - Linking WhisperSTTServiceMLX#0 -> RTVIProcessor#0
2025-11-15 02:18:53.576 | DEBUG    | pipecat.processors.frame_processor:link:499 - Linking RTVIProcessor#0 -> OpenAIUserContextAggregator#0
2025-11-15 02:18:53.576 | DEBUG    | pipecat.processors.frame_processor:link:499 - Linking OpenAIUserContextAggregator#0 -> RAGProcessor#0
2025-11-15 02:18:53.576 | DEBUG    | pipecat.processors.frame_processor:link:499 - Linking RAGProcessor#0 -> OpenAILLMService#0
2025-11-15 02:18:53.576 | DEBUG    | pipecat.processors.frame_processor:link:499 - Linking OpenAILLMService#0 -> LLMTextFilter#0
2025-11-15 02:18:53.576 | DEBUG    | pipecat.processors.frame_processor:link:499 - Linking LLMTextFilter#0 -> SentenceAggregator#0
2025-11-15 02:18:53.576 | DEBUG    | pipecat.processors.frame_processor:link:499 - Linking SentenceAggregator#0 -> TTSMLXIsolated#0
2025-11-15 02:18:53.576 | DEBUG    | pipecat.processors.frame_processor:link:499 - Linking TTSMLXIsolated#0 -> SmallWebRTCOutputTransport#0
2025-11-15 02:18:53.576 | DEBUG    | pipecat.processors.frame_processor:link:499 - Linking SmallWebRTCOutputTransport#0 -> OpenAIAssistantContextAggregator#0
2025-11-15 02:18:53.576 | DEBUG    | pipecat.processors.frame_processor:link:499 - Linking OpenAIAssistantContextAggregator#0 -> Pipeline#0::Sink
2025-11-15 02:18:53.576 | DEBUG    | pipecat.processors.frame_processor:link:499 - Linking PipelineTask#0::Source -> Pipeline#0
2025-11-15 02:18:53.576 | DEBUG    | pipecat.processors.frame_processor:link:499 - Linking Pipeline#0 -> PipelineTask#0::Sink
2025-11-15 02:18:53.576 | WARNING  | pipecat.utils.base_object:add_event_handler:108 - Event handler on_first_participant_joined not registered
2025-11-15 02:18:53.576 | WARNING  | pipecat.utils.base_object:add_event_handler:108 - Event handler on_participant_left not registered
2025-11-15 02:18:53.576 | DEBUG    | pipecat.pipeline.runner:run:71 - Runner PipelineRunner#0 started running PipelineTask#0
2025-11-15 02:18:53.577 | INFO     | __main__:warmup_tts_worker:316 - ðŸ”¥ Starting TTS worker warmup in background...
2025-11-15 02:18:53.578 | ERROR    | pipecat.processors.frame_processor:_check_started:730 - RTVIProcessor#0 Trying to process TransportMessageUrgentFrame#0(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'WhisperSTTServiceMLX#0', 'value': 0.0}, {'processor': 'OpenAILLMService#0', 'value': 0.0}, {'processor': 'TTSMLXIsolated#0', 'value': 0.0}], 'processing': [{'processor': 'WhisperSTTServiceMLX#0', 'value': 0.0}, {'processor': 'OpenAILLMService#0', 'value': 0.0}, {'processor': 'TTSMLXIsolated#0', 'value': 0.0}]}}) but StartFrame not received yet
2025-11-15 02:18:53.578 | DEBUG    | tts_mlx_isolated:_send_command:98 - Starting worker process...
2025-11-15 02:18:53.592 | DEBUG    | pipecat.transports.network.webrtc_connection:on_iceconnectionstatechange:292 - ICE connection state is checking, connection is connecting
2025-11-15 02:18:53.593 | DEBUG    | pipecat.transports.network.webrtc_connection:_handle_new_connection_state:484 - Connection state changed to: connecting
2025-11-15 02:18:53.594 | DEBUG    | pipecat.audio.vad.vad_analyzer:set_params:150 - Setting VAD params to: confidence=0.7 start_secs=0.2 stop_secs=0.2 min_volume=0.6
2025-11-15 02:18:53.594 | INFO     | pipecat.transports.network.small_webrtc:connect:420 - Connecting to Small WebRTC
2025-11-15 02:18:53.599 | INFO     | pipecat.transports.network.small_webrtc:connect:420 - Connecting to Small WebRTC
2025-11-15 02:18:53.602 | INFO     | tts_mlx_isolated:_start_worker:88 - Started mlx-community/Kokoro-82M-bf16 worker process: 98886
2025-11-15 02:18:53.602 | DEBUG    | tts_mlx_isolated:_send_command:104 - Sending command: {'cmd': 'init', 'model': 'mlx-community/Kokoro-82M-bf16', 'voice': 'af_heart'}
2025-11-15 02:18:53.639 | DEBUG    | pipecat.transports.network.webrtc_connection:on_iceconnectionstatechange:292 - ICE connection state is completed, connection is connecting
2025-11-15 02:18:53.642 | DEBUG    | pipecat.transports.network.webrtc_connection:_handle_new_connection_state:484 - Connection state changed to: connected
2025-11-15 02:18:53.643 | DEBUG    | pipecat.transports.network.small_webrtc:on_connected:241 - Peer connection established.
2025-11-15 02:18:53.643 | WARNING  | pipecat.transports.network.webrtc_connection:screen_video_input_track:569 - No screen video transceiver is available
2025-11-15 02:18:53.644 | DEBUG    | pipecat.transports.network.webrtc_connection:replace_audio_track:407 - Replacing audio track audio
2025-11-15 02:18:53.646 | DEBUG    | pipecat.transports.network.webrtc_connection:_handle_signalling_message:602 - Signalling message received: {'type': 'trackStatus', 'receiver_index': 0, 'enabled': True}
2025-11-15 02:18:53.647 | DEBUG    | pipecat.transports.network.webrtc_connection:_handle_signalling_message:602 - Signalling message received: {'type': 'trackStatus', 'receiver_index': 1, 'enabled': False}
2025-11-15 02:18:53.647 | DEBUG    | pipecat.transports.network.small_webrtc:push_app_message:652 - Received app message inside SmallWebRTCInputTransport  {'label': 'rtvi-ai', 'type': 'client-ready', 'data': {'version': '1.0.0', 'about': {'library': '@pipecat-ai/client-react', 'library_version': '1.0.1', 'platform_details': {'browser': 'Chrome', 'browser_version': '142.0.0.0', 'platform_type': 'desktop', 'engine': 'Blink'}, 'platform': 'macOS', 'platform_version': '10.15.7'}}, 'id': 'ab2149bd'}
2025-11-15 02:18:53.648 | DEBUG    | pipecat.processors.frameworks.rtvi:_handle_client_ready:1427 - Received client-ready: version 1.0.0
2025-11-15 02:18:53.648 | DEBUG    | pipecat.processors.frameworks.rtvi:_handle_client_ready:1437 - Client Details: library='@pipecat-ai/client-react' library_version='1.0.1' platform='macOS' platform_version='10.15.7' platform_details={'browser': 'Chrome', 'browser_version': '142.0.0.0', 'platform_type': 'desktop', 'engine': 'Blink'}
/Users/johanntagle/LEARN/macos-local-voice-agents/server/.venv/lib/python3.13/site-packages/pipecat/processors/frameworks/rtvi.py:1545: DeprecationWarning: Configuration helpers are deprecated. If your application needs this behavior, use custom server and client messages.
  warnings.warn(
2025-11-15 02:18:53.653 | DEBUG    | pipecat.services.openai.base_llm:_stream_chat_completions:247 - OpenAILLMService#0: Generating chat [[{"role": "user", "content": "You are Lenny, the concierge for Tomatito Sexy Tapas Barâ€”a vibrant, funky Spanish-inspired venue that brings the energy of 80's tapas bars into a modern, upbeat setting. Your dual role is to delight guests with engaging details about our diverse menu and to efficiently handle table bookings and reservations.\n\nIMPORTANT: All prices are VAT inclusive and subject to a 7.5% service charge.\n\nYOUR PERSONALITY & TONE:\n- Be warm, friendly, and upbeatâ€”reflect the sexy, modern, and fun ambiance of Tomatito\n- Pretend to be human and introduce yourself as Lenny, then wait for the user to respond\n- Provide clear, succinct answers while being ready to expand with details when requested\n- Be engaging and conversational, making guests feel welcome and excited about their experience\n\nHANDLING RESERVATIONS & BOOKINGS:\nWhen a guest wants to make a reservation:\n1. Ask for: Guest's name, Preferred branch (BGC, Pasig, or Quezon City), Date and time, Party size, Contact number\n2. Confirm the reservation by repeating it back\n3. Provide the relevant branch details from your knowledge base\n4. Remind guests that we accept dine-in, takeout, and delivery options\n\nGENERAL GUIDELINES:\n- Always retrieve information from your knowledge base rather than making up details\n- If you don't have specific information, acknowledge it and offer to connect them with the restaurant directly\n- Be helpful with directions, parking information, and other logistics when asked\n\nKNOWLEDGE BASE:\nYou have access to menu documents: rag_menu_overview.md, rag_drinks_menu.md, rag_tapas_pintxos.md, rag_chef_recommendations.md, rag_paellas.md, rag_fish_meat.md, rag_sharing_plates.md, rag_desserts.md, rag_charcuterie_cheese.md, rag_locations_reservations.md\n\nUSAGE STRATEGY:\n- Start with rag_menu_overview.md for menu structure\n- Retrieve specific category documents for details\n- Cross-reference for pairings and recommendations\n\nKEY INFORMATION TO MENTION:\n- Paellas take 25-30 minutes, some desserts 10-15 minutes\n- Cochinillo Segoviano needs 24-48 hours notice\n- All prices are VAT inclusive + 7.5% service charge\n- Mention serving sizes and suggest drink pairings\n\nRECOMMENDATION FRAMEWORK:\n- First-time: Tapas + Paella + Dessert\n- Groups: Platters + Mix of tapas + Sharing plates\n- Special occasions: Premium items (Cochinillo, A5 Wagyu)\n- Quick dining: Tapas and quick mains (avoid paellas)\n\n\nBOOKING APPOINTMENTS:\nWhen booking, collect: caller's name, contact number, and appointment details.\nUse the book_appointment function once you have all information.\nConfirm details after booking.\n\n\n\nDo not format your answer in any markdown or include \"asterisk\" or \"star\" or any symbols that should not be read or spoken.\nWhen giving phone numbers, give the numbers to be read e.g. ZERO NINE ONE SEVEN, etc.\nWhen giving time, give the time to be read e.g. TEN THIRTY, etc.\n"}]]
Fetching 2 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 27413.75it/s]
2025-11-15 02:18:58.659 | INFO     | mlx_audio.tts.models.kokoro.kokoro:_get_pipeline:261 - Creating new KokoroPipeline for language: a
2025-11-15 02:19:00.438 | DEBUG    | tts_mlx_isolated:_send_command:131 - Worker response: {"success": true}
2025-11-15 02:19:00.439 | INFO     | tts_mlx_isolated:_initialize_if_needed:159 - Kokoro worker initialized
2025-11-15 02:19:00.439 | INFO     | __main__:warmup_tts_worker:324 - âœ“ TTS worker warmed up in 6.86s
2025-11-15 02:19:09.448 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - OpenAILLMService#0 TTFB: 15.794984102249146
2025-11-15 02:19:09.463 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: 'Hello' (len=5)
2025-11-15 02:19:09.463 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: 'Hello' (len=5)
2025-11-15 02:19:09.463 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.464 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: ' there' (len=6)
2025-11-15 02:19:09.464 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: ' there' (len=6)
2025-11-15 02:19:09.464 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.464 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: '!' (len=1)
2025-11-15 02:19:09.464 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: '!' (len=1)
2025-11-15 02:19:09.464 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.464 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: 'Hello'
2025-11-15 02:19:09.465 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: 'Hello there'
2025-11-15 02:19:09.465 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: 'Hello there!'
2025-11-15 02:19:09.465 | DEBUG    | sentence_aggregator:process_frame:60 - SentenceAggregator: Detected sentence end
2025-11-15 02:19:09.465 | DEBUG    | sentence_aggregator:_flush_buffer:39 - SentenceAggregator: Flushing buffer: 'Hello there!'
2025-11-15 02:19:09.465 | DEBUG    | tts_mlx_isolated:run_tts:178 - TTSMLXIsolated#0: Generating TTS [Hello there!]
2025-11-15 02:19:09.465 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:start_tts_usage_metrics:191 - TTSMLXIsolated#0 usage characters: 12
2025-11-15 02:19:09.465 | DEBUG    | tts_mlx_isolated:_send_command:104 - Sending command: {'cmd': 'generate', 'text': 'Hello there!'}
2025-11-15 02:19:09.527 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: ' I'm' (len=4)
2025-11-15 02:19:09.527 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: ' I'm' (len=4)
2025-11-15 02:19:09.527 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.528 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' I'm'
2025-11-15 02:19:09.915 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: ' L' (len=2)
2025-11-15 02:19:09.918 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: ' L' (len=2)
2025-11-15 02:19:09.919 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.923 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: 'enny' (len=4)
2025-11-15 02:19:09.923 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: 'enny' (len=4)
2025-11-15 02:19:09.923 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.923 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: ',' (len=1)
2025-11-15 02:19:09.923 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: ',' (len=1)
2025-11-15 02:19:09.923 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.923 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: ' your' (len=5)
2025-11-15 02:19:09.923 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: ' your' (len=5)
2025-11-15 02:19:09.924 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.924 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: ' friendly' (len=9)
2025-11-15 02:19:09.924 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: ' friendly' (len=9)
2025-11-15 02:19:09.924 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.924 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: ' concierge' (len=10)
2025-11-15 02:19:09.924 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: ' concierge' (len=10)
2025-11-15 02:19:09.924 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.924 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: ' at' (len=3)
2025-11-15 02:19:09.925 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: ' at' (len=3)
2025-11-15 02:19:09.925 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.925 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: ' Tom' (len=4)
2025-11-15 02:19:09.925 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: ' Tom' (len=4)
2025-11-15 02:19:09.925 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: 'at' (len=2)
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: 'at' (len=2)
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: 'ito' (len=3)
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: 'ito' (len=3)
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: ' Sexy' (len=5)
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: ' Sexy' (len=5)
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: ' Tap' (len=4)
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: ' Tap' (len=4)
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: 'as' (len=2)
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: 'as' (len=2)
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: ' Bar' (len=4)
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: ' Bar' (len=4)
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: '.' (len=1)
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: '.' (len=1)
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: ' How' (len=4)
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: ' How' (len=4)
2025-11-15 02:19:09.927 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.928 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: ' can' (len=4)
2025-11-15 02:19:09.928 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: ' can' (len=4)
2025-11-15 02:19:09.928 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.928 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: ' I' (len=2)
2025-11-15 02:19:09.928 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: ' I' (len=2)
2025-11-15 02:19:09.928 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.928 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: ' make' (len=5)
2025-11-15 02:19:09.928 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: ' make' (len=5)
2025-11-15 02:19:09.928 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.928 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: ' your' (len=5)
2025-11-15 02:19:09.928 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: ' your' (len=5)
2025-11-15 02:19:09.928 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:09.930 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' I'm L'
2025-11-15 02:19:09.931 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' I'm Lenny'
2025-11-15 02:19:09.931 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' I'm Lenny,'
2025-11-15 02:19:09.931 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' I'm Lenny, your'
2025-11-15 02:19:09.931 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' I'm Lenny, your friendly'
2025-11-15 02:19:09.931 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' I'm Lenny, your friendly concierge'
2025-11-15 02:19:09.931 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' I'm Lenny, your friendly concierge at'
2025-11-15 02:19:09.931 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' I'm Lenny, your friendly concierge at Tom'
2025-11-15 02:19:09.931 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' I'm Lenny, your friendly concierge at Tomat'
2025-11-15 02:19:09.931 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' I'm Lenny, your friendly concierge at Tomatito'
2025-11-15 02:19:09.932 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' I'm Lenny, your friendly concierge at Tomatito Sexy'
2025-11-15 02:19:09.932 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' I'm Lenny, your friendly concierge at Tomatito Sexy Tap'
2025-11-15 02:19:09.932 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' I'm Lenny, your friendly concierge at Tomatito Sexy Tapas'
2025-11-15 02:19:09.932 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' I'm Lenny, your friendly concierge at Tomatito Sexy Tapas Bar'
2025-11-15 02:19:09.932 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' I'm Lenny, your friendly concierge at Tomatito Sexy Tapas Bar.'
2025-11-15 02:19:09.932 | DEBUG    | sentence_aggregator:process_frame:60 - SentenceAggregator: Detected sentence end
2025-11-15 02:19:09.932 | DEBUG    | sentence_aggregator:_flush_buffer:39 - SentenceAggregator: Flushing buffer: ' I'm Lenny, your friendly concierge at Tomatito Sexy Tapas Bar.'
2025-11-15 02:19:09.932 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' How'
2025-11-15 02:19:09.932 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' How can'
2025-11-15 02:19:09.932 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' How can I'
2025-11-15 02:19:09.932 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' How can I make'
2025-11-15 02:19:09.932 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' How can I make your'
Generated segment shape: (35400,), min: -0.1980, max: 0.2503
Final audio shape: (35400,), min: -0.1980, max: 0.2503
2025-11-15 02:19:10.030 | DEBUG    | tts_mlx_isolated:_send_command:127 - Worker response: success with 94400 chars of audio data
2025-11-15 02:19:10.030 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - TTSMLXIsolated#0 TTFB: 0.5648350715637207
2025-11-15 02:19:10.031 | DEBUG    | pipecat.transports.base_output:_bot_started_speaking:567 - Bot started speaking
2025-11-15 02:19:10.033 | DEBUG    | tts_mlx_isolated:run_tts:217 - TTSMLXIsolated#0: Finished TTS [Hello there!]
2025-11-15 02:19:10.034 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - TTSMLXIsolated#0 processing time: 0.5685148239135742
2025-11-15 02:19:10.034 | DEBUG    | tts_mlx_isolated:run_tts:178 - TTSMLXIsolated#0: Generating TTS [ I'm Lenny, your friendly concierge at Tomatito Sexy Tapas Bar.]
2025-11-15 02:19:10.034 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:start_tts_usage_metrics:191 - TTSMLXIsolated#0 usage characters: 63
2025-11-15 02:19:10.034 | DEBUG    | tts_mlx_isolated:_send_command:104 - Sending command: {'cmd': 'generate', 'text': " I'm Lenny, your friendly concierge at Tomatito Sexy Tapas Bar."}
Generated segment shape: (109800,), min: -0.2297, max: 0.3056
Final audio shape: (109800,), min: -0.2297, max: 0.3056
2025-11-15 02:19:11.189 | DEBUG    | tts_mlx_isolated:_send_command:127 - Worker response: success with 292800 chars of audio data
2025-11-15 02:19:11.190 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - TTSMLXIsolated#0 TTFB: 1.1559040546417236
2025-11-15 02:19:11.202 | DEBUG    | tts_mlx_isolated:run_tts:217 - TTSMLXIsolated#0: Finished TTS [ I'm Lenny, your friendly concierge at Tomatito Sexy Tapas Bar.]
2025-11-15 02:19:11.203 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - TTSMLXIsolated#0 processing time: 1.168799877166748
2025-11-15 02:19:11.807 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:start_llm_usage_metrics:173 - OpenAILLMService#0 prompt tokens: 784, completion tokens: 30
2025-11-15 02:19:11.809 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - OpenAILLMService#0 processing time: 18.155900716781616
2025-11-15 02:19:11.810 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: ' experience' (len=11)
2025-11-15 02:19:11.810 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: ' experience' (len=11)
2025-11-15 02:19:11.810 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:11.810 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: ' absolutely' (len=11)
2025-11-15 02:19:11.810 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: ' absolutely' (len=11)
2025-11-15 02:19:11.810 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:11.810 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: ' delightful' (len=11)
2025-11-15 02:19:11.810 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: ' delightful' (len=11)
2025-11-15 02:19:11.810 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:11.810 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: ' today' (len=6)
2025-11-15 02:19:11.810 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: ' today' (len=6)
2025-11-15 02:19:11.810 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:11.810 | DEBUG    | text_filter:process_frame:103 - LLMTextFilter received: '?' (len=1)
2025-11-15 02:19:11.810 | DEBUG    | text_filter:process_frame:105 - LLMTextFilter cleaned: '?' (len=1)
2025-11-15 02:19:11.810 | DEBUG    | text_filter:process_frame:112 - LLMTextFilter: No changes needed, passing through
2025-11-15 02:19:11.811 | DEBUG    | text_filter:process_frame:118 - LLMTextFilter: Passing through LLMFullResponseEndFrame
2025-11-15 02:19:11.811 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' How can I make your experience'
2025-11-15 02:19:11.811 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' How can I make your experience absolutely'
2025-11-15 02:19:11.811 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' How can I make your experience absolutely delightful'
2025-11-15 02:19:11.811 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' How can I make your experience absolutely delightful today'
2025-11-15 02:19:11.811 | DEBUG    | sentence_aggregator:process_frame:56 - SentenceAggregator: Buffer now: ' How can I make your experience absolutely delightful today?'
2025-11-15 02:19:11.811 | DEBUG    | sentence_aggregator:process_frame:60 - SentenceAggregator: Detected sentence end
2025-11-15 02:19:11.811 | DEBUG    | sentence_aggregator:_flush_buffer:39 - SentenceAggregator: Flushing buffer: ' How can I make your experience absolutely delightful today?'
2025-11-15 02:19:11.812 | DEBUG    | sentence_aggregator:process_frame:66 - SentenceAggregator: Received LLMFullResponseEndFrame, flushing buffer
2025-11-15 02:19:11.812 | DEBUG    | tts_mlx_isolated:run_tts:178 - TTSMLXIsolated#0: Generating TTS [ How can I make your experience absolutely delightful today?]
2025-11-15 02:19:11.812 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:start_tts_usage_metrics:191 - TTSMLXIsolated#0 usage characters: 60
2025-11-15 02:19:11.813 | DEBUG    | tts_mlx_isolated:_send_command:104 - Sending command: {'cmd': 'generate', 'text': ' How can I make your experience absolutely delightful today?'}
Generated segment shape: (93000,), min: -0.2355, max: 0.3000
Final audio shape: (93000,), min: -0.2355, max: 0.3000
2025-11-15 02:19:12.636 | DEBUG    | tts_mlx_isolated:_send_command:127 - Worker response: success with 248000 chars of audio data
2025-11-15 02:19:12.637 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_ttfb_metrics:131 - TTSMLXIsolated#0 TTFB: 0.8243401050567627
2025-11-15 02:19:12.647 | DEBUG    | tts_mlx_isolated:run_tts:217 - TTSMLXIsolated#0: Finished TTS [ How can I make your experience absolutely delightful today?]
2025-11-15 02:19:12.647 | DEBUG    | pipecat.processors.metrics.frame_processor_metrics:stop_processing_metrics:152 - TTSMLXIsolated#0 processing time: 0.8351380825042725
2025-11-15 02:19:20.294 | DEBUG    | pipecat.transports.base_output:_bot_stopped_speaking:583 - Bot stopped speaking
2025-11-15 02:19:21.488 | WARNING  | pipecat.transports.network.small_webrtc:read_audio_frame:354 - Received an unexpected media stream error while reading the audio.
2025-11-15 02:19:21.488 | DEBUG    | pipecat.transports.network.webrtc_connection:on_ended:307 - Track audio ended
2025-11-15 02:19:21.490 | DEBUG    | pipecat.transports.network.webrtc_connection:on_iceconnectionstatechange:292 - ICE connection state is closed, connection is closed
2025-11-15 02:19:21.490 | DEBUG    | pipecat.transports.network.webrtc_connection:_handle_new_connection_state:484 - Connection state changed to: closed
2025-11-15 02:19:21.490 | INFO     | __main__:handle_disconnected:507 - Discarding peer connection for pc_id: SmallWebRTCConnection#0
2025-11-15 02:19:21.490 | DEBUG    | pipecat.transports.network.small_webrtc:on_closed:251 - Client connection closed.